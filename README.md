This project focuses on developing a hand gesture recognition system using OpenCV, cvzone, and a pre-trained Keras model. The system comprises two main components: data collection and gesture classification. In the data collection phase (`datacollection.py`), the script captures hand images via webcam, isolates the hand region, and processes it by resizing and centering it on a white background for consistent training data. These processed images are saved in a specified folder with unique timestamps. The gesture classification phase (`test.py`) leverages a pre-trained Keras model to classify hand gestures in real-time. The script captures hand images from the webcam, preprocesses them similarly to the data collection phase, and uses the trained model to predict the gesture. The predicted gesture label is then displayed on the video feed. The system is designed to recognize gestures such as "hello," "thank you," "love you," and "yes." This project demonstrates the integration of computer vision, machine learning, and real-time image processing to create an intuitive hand gesture recognition application.
